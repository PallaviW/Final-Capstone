{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Twitter sentiments for Self-driving cars\n",
    "\n",
    "Based on given train data, we need to classify tweets about driverless cars as from very positive to very negative. \n",
    "\n",
    "5 - very positive\n",
    "\n",
    "4 - slightly positive\n",
    "\n",
    "3 - neutral\n",
    "\n",
    "2 - slightly negative\n",
    "\n",
    "1 - very negative\n",
    "\n",
    "There are train and test datasets.\n",
    "\n",
    "#### Acknowledgements\n",
    "\n",
    "Thanks crowdflower.com, for providing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, Word2Vec\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "\n",
    "# these imports are how we build and manager our data science processes: cleaning data, preparing a model,\n",
    "# executing the model, and evaluating the model.\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import functools\n",
    "%matplotlib inline\n",
    "\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "## constants\n",
    "DATA_NAME = \"/home/ds/notebooks/datasets/Twitter_data/train.csv\"\n",
    "APP_NAME = \"Sentiment Analysis with tweets\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "RANDOM_SEED = 141107\n",
    "TRAINING_DATA_RATIO = 0.8\n",
    "RF_NUM_TREES = 200\n",
    "RF_MAX_DEPTH = 4\n",
    "RF_NUM_BINS = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data = sqlContext.read.csv(DATA_NAME, header=True, mode=\"DROPMALFORMED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|sentiment|                text|\n",
      "+---------+--------------------+\n",
      "|        5|@manjulamartin @K...|\n",
      "|        5|I want a Google d...|\n",
      "|        5|@Oatmeal @google ...|\n",
      "|        5|SO MUCH AWESOME! ...|\n",
      "|        5|@google is making...|\n",
      "|        5|You could call a ...|\n",
      "|        5|Ì¢‰âÂÒ@Marketpla...|\n",
      "|        5|Driverless taxis ...|\n",
      "|        5|This whole @googl...|\n",
      "|        5|Google's New Driv...|\n",
      "|        5|Riding in a drive...|\n",
      "|        5|This is the futur...|\n",
      "|        5|@NicoleLapin The ...|\n",
      "|        5|This is why we ne...|\n",
      "|        5|Google developed ...|\n",
      "|        5|@WOKVNews @jax_fl...|\n",
      "|        5|They're coming ou...|\n",
      "|        5|I want a driverle...|\n",
      "|        5|Driverless cars c...|\n",
      "|        5|#SKYNET Ì¢‰âÂÒ@S...|\n",
      "+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "967"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data = tweets_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "967"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As data analysis shows that there are no null records also data is in texual format we can not perform prediction modelling on data unless we convert that data to numeric values. we have to extract features from text data to analyze it. Lets vizualize data first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql.types import IntegerType\n",
    "#tweets_data = tweets_data.withColumn(\"sentiment\", tweets_data[\"sentiment\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "967"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to handle sentiments\n",
    "#def tweeter_sentiment(x):\n",
    "    #if x > 3:  #sentiments with very positive, slightly positive\n",
    "     #   return 2\n",
    "    #elif x < 3: #sentiments with slightly negative, very negative\n",
    "        #return 1\n",
    "    #else:\n",
    "        #return 0 #sentiments with neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "#func_udf = udf(tweeter_sentiment, IntegerType())\n",
    "#tweets_data = tweets_data.withColumn('sentiment_encoded',func_udf(tweets_data['sentiment'].cast(IntegerType())))\n",
    "tweets_data = tweets_data.withColumn('sentiment_encoded',tweets_data['sentiment'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------------+\n",
      "|sentiment|                text|sentiment_encoded|\n",
      "+---------+--------------------+-----------------+\n",
      "|        5|@manjulamartin @K...|                5|\n",
      "|        5|I want a Google d...|                5|\n",
      "|        5|@Oatmeal @google ...|                5|\n",
      "|        5|SO MUCH AWESOME! ...|                5|\n",
      "|        5|@google is making...|                5|\n",
      "+---------+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|sentiment_encoded|count|\n",
      "+-----------------+-----+\n",
      "|                1|   23|\n",
      "|                3|  595|\n",
      "|                5|   57|\n",
      "|                4|  177|\n",
      "|                2|  115|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "statuses = tweets_data.groupBy('sentiment_encoded').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(sentiment='3', count=595), Row(sentiment='5', count=57), Row(sentiment='1', count=23), Row(sentiment='4', count=177), Row(sentiment='2', count=115)]\n",
      "['3', '5', '1', '4', '2']\n",
      "['neutral', 'very positive', 'very negative', 'slightly positive', 'slightly negative']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7f0fb8069a90>,\n",
       "  <matplotlib.axis.XTick at 0x7f0fb80f1c18>,\n",
       "  <matplotlib.axis.XTick at 0x7f0fb80f5dd8>,\n",
       "  <matplotlib.axis.XTick at 0x7f0fb19f4630>,\n",
       "  <matplotlib.axis.XTick at 0x7f0fbc814710>],\n",
       " <a list of 5 Text xticklabel objects>)"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0fbc7ae358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    " \n",
    "#statuses = tweets_data.groupBy('sentiment_encoded').count().collect()\n",
    "statuses = tweets_data.groupBy('sentiment').count().collect()\n",
    "print(statuses)\n",
    "categories = [i[0] for i in statuses]\n",
    "counts = [i[1] for i in statuses]\n",
    "display_label = []\n",
    "\n",
    "#for item in categories:\n",
    "    #if item == 1:\n",
    "        #display_label.append('negative')\n",
    "    #elif item == 2:\n",
    "       # display_label.append('positive')\n",
    "    #else:\n",
    "        #display_label.append('neutral')\n",
    "print(categories)\n",
    "for item in categories:\n",
    "    if item == '5':\n",
    "        display_label.append('very positive')\n",
    "    elif item == '4':\n",
    "        display_label.append('slightly positive')\n",
    "    elif item == '3':\n",
    "        display_label.append('neutral')\n",
    "    elif item == '2':\n",
    "        display_label.append('slightly negative')\n",
    "    else:\n",
    "        display_label.append('very negative')\n",
    "        \n",
    "print(display_label)        \n",
    "ind = np.array(range(len(categories)))\n",
    "width = 0.35\n",
    "plt.bar(ind, counts, width=width, color='gyc')\n",
    " \n",
    "plt.ylabel('counts')\n",
    "plt.title('distribution')\n",
    "plt.xticks(ind, display_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph shows that sentiment for self driving car tweets is more of neutral compared to positive or negative. Lets find out some features for predictive modelling on the twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try different techniques for feature engineering like word2vec or Tf/Idf to make data ready for predictive modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = Tokenizer(inputCol=\"text\", outputCol=\"tokenized_text\").transform(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Vec = Word2Vec(vectorSize=300, seed=42, inputCol=\"tokenized_text\", outputCol=\"w2v_vector\").fit(tokenized_data)\n",
    "w2vdf=word2Vec.transform(tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- sentiment_encoded: integer (nullable = true)\n",
      " |-- tokenized_text: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- w2v_vector: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w2vdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+--------------------+\n",
      "|sentiment|                text|      tokenized_text|          w2v_vector|\n",
      "+---------+--------------------+--------------------+--------------------+\n",
      "|        5|@manjulamartin @K...|[@manjulamartin, ...|[0.00195620217564...|\n",
      "|        5|I want a Google d...|[i, want, a, goog...|[0.01613896682101...|\n",
      "|        5|@Oatmeal @google ...|[@oatmeal, @googl...|[0.01142727420665...|\n",
      "|        5|SO MUCH AWESOME! ...|[so, much, awesom...|[0.00425823115898...|\n",
      "|        5|@google is making...|[@google, is, mak...|[0.00704800314916...|\n",
      "|        5|You could call a ...|[you, could, call...|[0.00506992266807...|\n",
      "|        5|Ì¢‰âÂÒ@Marketpla...|[ì¢‰ââò@marketpl...|[0.00591101296330...|\n",
      "|        5|Driverless taxis ...|[driverless, taxi...|[0.01109385670618...|\n",
      "|        5|This whole @googl...|[this, whole, @go...|[0.00681427969935...|\n",
      "|        5|Google's New Driv...|[google's, new, d...|[0.00581081371961...|\n",
      "|        5|Riding in a drive...|[riding, in, a, d...|[0.00700959832722...|\n",
      "|        5|This is the futur...|[this, is, the, f...|[0.00538454561716...|\n",
      "|        5|@NicoleLapin The ...|[@nicolelapin, th...|[0.00541953135398...|\n",
      "|        5|This is why we ne...|[this, is, why, w...|[0.00911802430346...|\n",
      "|        5|Google developed ...|[google, develope...|[0.01002116555658...|\n",
      "|        5|@WOKVNews @jax_fl...|[@wokvnews, @jax_...|[0.00388369919382...|\n",
      "|        5|They're coming ou...|[they're, coming,...|[0.01400958408339...|\n",
      "|        5|I want a driverle...|[i, want, a, driv...|[0.01214915075356...|\n",
      "|        5|Driverless cars c...|[driverless, cars...|[0.00659389075423...|\n",
      "|        5|#SKYNET Ì¢‰âÂÒ@S...|[#skynet, ì¢‰ââò...|[0.00504870647670...|\n",
      "+---------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w2vdf.select('sentiment','text','tokenized_text','w2v_vector').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF/IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"tokenized_text\", outputCol=\"tfidf_vector\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"tfidf_vector\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "tfidf_df = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------------+--------------------+--------------------+--------------------+\n",
      "|sentiment|                text|sentiment_encoded|      tokenized_text|        tfidf_vector|            features|\n",
      "+---------+--------------------+-----------------+--------------------+--------------------+--------------------+\n",
      "|        5|@manjulamartin @K...|                5|[@manjulamartin, ...|(20,[0,2,3,4,6,7,...|(20,[0,2,3,4,6,7,...|\n",
      "|        5|I want a Google d...|                5|[i, want, a, goog...|(20,[0,9,10,12,16...|(20,[0,9,10,12,16...|\n",
      "|        5|@Oatmeal @google ...|                5|[@oatmeal, @googl...|(20,[0,1,3,4,9,10...|(20,[0,1,3,4,9,10...|\n",
      "|        5|SO MUCH AWESOME! ...|                5|[so, much, awesom...|(20,[0,2,4,5,6,8,...|(20,[0,2,4,5,6,8,...|\n",
      "|        5|@google is making...|                5|[@google, is, mak...|(20,[0,1,8,10,16,...|(20,[0,1,8,10,16,...|\n",
      "+---------+--------------------+-----------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we tried different ways for feature extraction, lets try to perform random forest classifier on those datasets to see which one performs better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training indexers/split data/classifier\n",
    "# first we'll generate a labelIndexer\n",
    "labelIndexer = StringIndexer(inputCol=\"sentiment\", outputCol=\"indexedLabel\").fit(w2vdf)\n",
    "\n",
    "# now generate the indexed feature vector.\n",
    "featureIndexer = VectorIndexer(inputCol=\"w2v_vector\", outputCol=\"indexedFeatures\", maxCategories=5).fit(w2vdf)\n",
    "    \n",
    "# Split the data into training and validation sets (30% held out for testing)\n",
    "(trainingData, testData) = w2vdf.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=RF_NUM_TREES)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+----------+--------------+\n",
      "|sentiment|          w2v_vector|         probability|prediction|predictedLabel|\n",
      "+---------+--------------------+--------------------+----------+--------------+\n",
      "|        1|[0.00788420691969...|[0.70060010928181...|       0.0|             3|\n",
      "|        1|[0.00346490017060...|[0.48143189791398...|       0.0|             3|\n",
      "|        1|[0.00354269497936...|[0.47950792966792...|       0.0|             3|\n",
      "|        1|[0.00801549779716...|[0.56599194509255...|       0.0|             3|\n",
      "|        1|[0.00495200723697...|[0.50674446432616...|       0.0|             3|\n",
      "|        2|[0.00483414915177...|[0.56832170403602...|       0.0|             3|\n",
      "|        2|[0.00671476894058...|[0.63137778109392...|       0.0|             3|\n",
      "|        2|[0.00264964997009...|[0.49337217972828...|       0.0|             3|\n",
      "|        2|[-0.0014114782639...|[0.53884055254912...|       0.0|             3|\n",
      "|        2|[0.00561993133887...|[0.59094125020295...|       0.0|             3|\n",
      "+---------+--------------------+--------------------+----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('sentiment','w2v_vector','probability','prediction','predictedLabel').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- sentiment_encoded: integer (nullable = true)\n",
      " |-- tokenized_text: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- w2v_vector: vector (nullable = true)\n",
      " |-- indexedLabel: double (nullable = true)\n",
      " |-- indexedFeatures: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      " |-- predictedLabel: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.369048\n",
      "Accuracy = 0.630952\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
    "print(f\"Accuracy = {accuracy:g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "      <th>very positive</th>\n",
       "      <th>very negative</th>\n",
       "      <th>slightly positive</th>\n",
       "      <th>slightly negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very positive</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very negative</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slightly positive</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slightly negative</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   neutral  very positive  very negative  slightly positive  \\\n",
       "neutral                  0              0              5                  0   \n",
       "very positive            0              0             21                  0   \n",
       "very negative            0              0            106                  0   \n",
       "slightly positive        0              0             28                  0   \n",
       "slightly negative        0              0              8                  0   \n",
       "\n",
       "                   slightly negative  \n",
       "neutral                            0  \n",
       "very positive                      0  \n",
       "very negative                      0  \n",
       "slightly positive                  0  \n",
       "slightly negative                  0  "
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(predictions.select('sentiment').collect(), \n",
    "             predictions.select('predictedLabel').collect()),\n",
    "             columns = display_label, \n",
    "             index= display_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with TF/IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training indexers/split data/classifier\n",
    "# first we'll generate a labelIndexer\n",
    "labelIndexer = StringIndexer(inputCol=\"sentiment\", outputCol=\"indexedLabel\").fit(tfidf_df)\n",
    "\n",
    "# now generate the indexed feature vector.\n",
    "featureIndexer = VectorIndexer(inputCol=\"tfidf_vector\", outputCol=\"indexedFeatures\", maxCategories=5).fit(tfidf_df)\n",
    "    \n",
    "# Split the data into training and validation sets (30% held out for testing)\n",
    "(trainingData_tf, testData_tf) = tfidf_df.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData_tf)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.364583\n",
      "Accuracy = 0.635417\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
    "print(f\"Accuracy = {accuracy:g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "      <th>very positive</th>\n",
       "      <th>very negative</th>\n",
       "      <th>slightly positive</th>\n",
       "      <th>slightly negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very positive</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very negative</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slightly positive</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slightly negative</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   neutral  very positive  very negative  slightly positive  \\\n",
       "neutral                  0              0              5                  0   \n",
       "very positive            0              0             17                  0   \n",
       "very negative            0              0            122                  0   \n",
       "slightly positive        0              0             37                  0   \n",
       "slightly negative        0              0             11                  0   \n",
       "\n",
       "                   slightly negative  \n",
       "neutral                            0  \n",
       "very positive                      0  \n",
       "very negative                      0  \n",
       "slightly positive                  0  \n",
       "slightly negative                  0  "
      ]
     },
     "execution_count": 736,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(predictions.select('sentiment').collect(), \n",
    "             predictions.select('predictedLabel').collect()),\n",
    "             columns = display_label, \n",
    "             index= display_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like Tf/idf data perform better with Random Forest compared to word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"w2v_vector\", labelCol=\"sentiment_encoded\",predictionCol=\"prediction\", maxIter=10,\n",
    "                        regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(trainingData)\n",
    "# Make predictions.\n",
    "predictions = lrModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.369048\n",
      "Accuracy = 0.630952\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"sentiment_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
    "print(f\"Accuracy = {accuracy:g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.369048\n",
      "Accuracy = 0.630952\n"
     ]
    }
   ],
   "source": [
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)\n",
    "             .build())\n",
    "# Create 5-fold CrossValidator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"sentiment_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "cv = CrossValidator(estimator=lr, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "cvModel = cv.fit(trainingData)\n",
    "\n",
    "predictions = cvModel.transform(testData)\n",
    "# Evaluate best model\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
    "print(f\"Accuracy = {accuracy:g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with TF/IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"sentiment_encoded\",predictionCol=\"prediction\", maxIter=10,\n",
    "                        regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "lrModel_tf = lr.fit(trainingData_tf)\n",
    "# Make predictions.\n",
    "predictions = lrModel_tf.transform(testData_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.364583\n",
      "Accuracy = 0.635417\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"sentiment_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
    "print(f\"Accuracy = {accuracy:g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.364583\n",
      "Accuracy = 0.635417\n"
     ]
    }
   ],
   "source": [
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)\n",
    "             .build())\n",
    "# Create 5-fold CrossValidator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"sentiment_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "cv = CrossValidator(estimator=lr, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "cvModel = cv.fit(trainingData_tf)\n",
    "\n",
    "predictions = cvModel.transform(testData_tf)\n",
    "# Evaluate best model\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
    "print(f\"Accuracy = {accuracy:g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "      <th>very positive</th>\n",
       "      <th>very negative</th>\n",
       "      <th>slightly positive</th>\n",
       "      <th>slightly negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very positive</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very negative</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slightly positive</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slightly negative</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   neutral  very positive  very negative  slightly positive  \\\n",
       "neutral                  0              0              5                  0   \n",
       "very positive            0              0             17                  0   \n",
       "very negative            0              0            122                  0   \n",
       "slightly positive        0              0             37                  0   \n",
       "slightly negative        0              0             11                  0   \n",
       "\n",
       "                   slightly negative  \n",
       "neutral                            0  \n",
       "very positive                      0  \n",
       "very negative                      0  \n",
       "slightly positive                  0  \n",
       "slightly negative                  0  "
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(predictions.select('sentiment_encoded').collect(), \n",
    "             predictions.select('prediction').collect()),\n",
    "             columns = display_label, \n",
    "             index= display_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(labelCol=\"sentiment_encoded\", featuresCol=\"features\", smoothing=1)\n",
    "model = nb.fit(trainingData_tf)\n",
    "predictions_nb = model.transform(testData_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|sentiment|                text|sentiment_encoded|      tokenized_text|        tfidf_vector|            features|       rawPrediction|         probability|prediction|\n",
      "+---------+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|        1|Also, cars with d...|                1|[also,, cars, wit...|(20,[0,1,4,5,8,10...|(20,[0,1,4,5,8,10...|[-34.991220382687...|[0.01345379266100...|       2.0|\n",
      "|        1|Driverless Cars: ...|                1|[driverless, cars...|(20,[0,1,4,5,6,8,...|(20,[0,1,4,5,6,8,...|[-34.326147156903...|[0.02871811555264...|       2.0|\n",
      "|        1|Driverless cars. ...|                1|[driverless, cars...|(20,[0,9,12,14,15...|(20,[0,9,12,14,15...|[-21.013147791562...|[0.03823751585407...|       2.0|\n",
      "|        1|Driverless cars?!...|                1|[driverless, cars...|(20,[0,1,4,5,6,8,...|(20,[0,1,4,5,6,8,...|[-21.695650402389...|[0.01671115811111...|       2.0|\n",
      "|        1|They're on about ...|                1|[they're, on, abo...|(20,[0,1,2,6,8,10...|(20,[0,1,2,6,8,10...|[-28.476939512158...|[0.03026552967789...|       2.0|\n",
      "+---------+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_nb.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.911458\n",
      "Accuracy = 0.0885417\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"sentiment_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions_nb)\n",
    "\n",
    "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
    "print(f\"Accuracy = {accuracy:g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "      <th>very positive</th>\n",
       "      <th>very negative</th>\n",
       "      <th>slightly positive</th>\n",
       "      <th>slightly negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very positive</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very negative</th>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slightly positive</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slightly negative</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   neutral  very positive  very negative  slightly positive  \\\n",
       "neutral                  0              5              0                  0   \n",
       "very positive            0             17              0                  0   \n",
       "very negative            0            122              0                  0   \n",
       "slightly positive        0             37              0                  0   \n",
       "slightly negative        0             11              0                  0   \n",
       "\n",
       "                   slightly negative  \n",
       "neutral                            0  \n",
       "very positive                      0  \n",
       "very negative                      0  \n",
       "slightly positive                  0  \n",
       "slightly negative                  0  "
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(predictions_nb.select('sentiment_encoded').collect(), \n",
    "             predictions_nb.select('prediction').collect()),\n",
    "             columns = display_label, \n",
    "             index= display_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA with word2vec data and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(k=100, inputCol=\"w2v_vector\", outputCol=\"pcaFeatures\")\n",
    "model = pca.fit(w2vdf)\n",
    "\n",
    "result = model.transform(w2vdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training indexers / split data / classifier\n",
    "# first we'll generate a labelIndexer\n",
    "labelIndexer = StringIndexer(inputCol=\"sentiment\", outputCol=\"indexedLabel\").fit(result)\n",
    "\n",
    "# now generate the indexed feature vector\n",
    "featureIndexer = VectorIndexer(inputCol=\"pcaFeatures\", outputCol=\"indexedFeatures\", maxCategories=4).fit(result)\n",
    "    \n",
    "# Split the data into training and validation sets (30% held out for testing)\n",
    "(pca_trainingData, pca_testData) = result.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=RF_NUM_TREES)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "pca_model = pipeline.fit(pca_trainingData)\n",
    "# Make predictions.\n",
    "pca_predictions = pca_model.transform(pca_testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.429319\n",
      "Accuracy = 0.570681\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(pca_predictions)\n",
    "\n",
    "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
    "print(f\"Accuracy = {accuracy:g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "      <th>very positive</th>\n",
       "      <th>very negative</th>\n",
       "      <th>slightly positive</th>\n",
       "      <th>slightly negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very positive</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very negative</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slightly positive</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slightly negative</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   neutral  very positive  very negative  slightly positive  \\\n",
       "neutral                  0              0              5                  0   \n",
       "very positive            0              0             26                  0   \n",
       "very negative            0              0            109                  0   \n",
       "slightly positive        0              0             41                  0   \n",
       "slightly negative        0              0             10                  0   \n",
       "\n",
       "                   slightly negative  \n",
       "neutral                            0  \n",
       "very positive                      0  \n",
       "very negative                      0  \n",
       "slightly positive                  0  \n",
       "slightly negative                  0  "
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(pca_predictions.select('sentiment').collect(), \n",
    "             pca_predictions.select('predictedLabel').collect()),\n",
    "             columns = display_label, \n",
    "             index= display_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA with tf/idf data and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(k=10, inputCol=\"tfidf_vector\", outputCol=\"pcaFeatures\")\n",
    "model = pca.fit(tfidf_df)\n",
    "\n",
    "result = model.transform(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training indexers / split data / classifier\n",
    "# first we'll generate a labelIndexer\n",
    "labelIndexer = StringIndexer(inputCol=\"sentiment\", outputCol=\"indexedLabel\").fit(result)\n",
    "\n",
    "# now generate the indexed feature vector\n",
    "featureIndexer = VectorIndexer(inputCol=\"pcaFeatures\", outputCol=\"indexedFeatures\", maxCategories=4).fit(result)\n",
    "    \n",
    "# Split the data into training and validation sets (30% held out for testing)\n",
    "(pca_trainingData_tf, pca_testData_tf) = result.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=RF_NUM_TREES)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.338462\n",
      "Accuracy = 0.661538\n"
     ]
    }
   ],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "pca_model = pipeline.fit(pca_trainingData_tf)\n",
    "# Make predictions.\n",
    "pca_predictions_tf = pca_model.transform(pca_testData_tf)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(pca_predictions_tf)\n",
    "\n",
    "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
    "print(f\"Accuracy = {accuracy:g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "      <th>very positive</th>\n",
       "      <th>very negative</th>\n",
       "      <th>slightly positive</th>\n",
       "      <th>slightly negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very positive</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very negative</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slightly positive</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slightly negative</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   neutral  very positive  very negative  slightly positive  \\\n",
       "neutral                  0              0              3                  0   \n",
       "very positive            0              0             21                  0   \n",
       "very negative            0              0            129                  0   \n",
       "slightly positive        0              0             34                  0   \n",
       "slightly negative        0              0              7                  1   \n",
       "\n",
       "                   slightly negative  \n",
       "neutral                            0  \n",
       "very positive                      0  \n",
       "very negative                      0  \n",
       "slightly positive                  0  \n",
       "slightly negative                  0  "
      ]
     },
     "execution_count": 769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(pca_predictions_tf.select('sentiment').collect(), \n",
    "             pca_predictions_tf.select('predictedLabel').collect()),\n",
    "             columns = display_label, \n",
    "             index= display_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA with tf/idf and Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------------+--------------------+--------------------+--------------------+\n",
      "|sentiment|                text|sentiment_encoded|      tokenized_text|          w2v_vector|         pcaFeatures|\n",
      "+---------+--------------------+-----------------+--------------------+--------------------+--------------------+\n",
      "|        1|\"\"\"Driver-less ca...|                1|[\"\"\"driver-less, ...|[0.00421577897903...|[-0.1158061037854...|\n",
      "|        1|\"8:28 AM - The dr...|                1|[\"8:28, am, -, th...|[0.00465906232737...|[-0.1097614065674...|\n",
      "|        1|@d3signerd Ì¢‰âÂå...|                1|[@d3signerd, ì¢‰â...|[0.00788420691969...|[-0.1494378231530...|\n",
      "|        1|@drgitlin yes, I ...|                1|[@drgitlin, yes,,...|[0.00661176691175...|[-0.1431551413024...|\n",
      "|        1|@google watched t...|                1|[@google, watched...|[0.00477988349040...|[-0.1040094240407...|\n",
      "+---------+--------------------+-----------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca_trainingData_tf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"pcaFeatures\", labelCol=\"sentiment_encoded\",predictionCol=\"prediction\", maxIter=10,\n",
    "                        regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.338462\n",
      "Accuracy = 0.661538\n"
     ]
    }
   ],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "pca_model = lr.fit(pca_trainingData_tf)\n",
    "# Make predictions.\n",
    "pca_predictions = pca_model.transform(pca_testData_tf)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"sentiment_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(pca_predictions)\n",
    "\n",
    "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
    "print(f\"Accuracy = {accuracy:g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA with Word2Vec and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(k=10, inputCol=\"w2v_vector\", outputCol=\"pca_w2v_Features\")\n",
    "model = pca.fit(w2vdf)\n",
    "\n",
    "result = model.transform(w2vdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training indexers / split data / classifier\n",
    "# first we'll generate a labelIndexer\n",
    "labelIndexer = StringIndexer(inputCol=\"sentiment_encoded\", outputCol=\"indexedLabel\").fit(result)\n",
    "\n",
    "# now generate the indexed feature vector\n",
    "featureIndexer = VectorIndexer(inputCol=\"pca_w2v_Features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(result)\n",
    "    \n",
    "# Split the data into training and validation sets (30% held out for testing)\n",
    "(pca_trainingData, pca_testData) = result.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=RF_NUM_TREES)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.42132\n",
      "Accuracy = 0.57868\n"
     ]
    }
   ],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "pca_model = pipeline.fit(pca_trainingData)\n",
    "pca_predictions = pca_model.transform(pca_testData)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(pca_predictions)\n",
    "\n",
    "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
    "print(f\"Accuracy = {accuracy:g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
